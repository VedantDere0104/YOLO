{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLO_v4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qke0XMVsGcoK"
      },
      "source": [
        "####"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYwsqxWcGe6F"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision import transforms\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c38Ut64zGopx"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcoyGKhxMZOP"
      },
      "source": [
        "def Reverse(lst):\n",
        "    return [ele for ele in reversed(lst)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCQDOLeTRHKe"
      },
      "source": [
        "def show_tensor_images(image_tensor, num_images=2, size=(3 , 416 , 416)):\n",
        "    image_shifted = image_tensor\n",
        "    image_unflat = image_shifted.detach().cpu().view(-1, *size)\n",
        "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
        "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQxCNtlCRJH6"
      },
      "source": [
        "def iou_width_height(boxes1, boxes2):\n",
        "\n",
        "    intersection = torch.min(boxes1[..., 0], boxes2[..., 0]) * torch.min(\n",
        "        boxes1[..., 1], boxes2[..., 1]\n",
        "    )\n",
        "    union = (\n",
        "        boxes1[..., 0] * boxes1[..., 1] + boxes2[..., 0] * boxes2[..., 1] - intersection\n",
        "    )\n",
        "    return intersection / union"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xO4rFpoPRLYk"
      },
      "source": [
        "def intersection_over_union(boxes_preds, boxes_labels, box_format=\"midpoint\"):\n",
        "\n",
        "    if box_format == \"midpoint\":\n",
        "        box1_x1 = boxes_preds[..., 0:1] - boxes_preds[..., 2:3] / 2\n",
        "        box1_y1 = boxes_preds[..., 1:2] - boxes_preds[..., 3:4] / 2\n",
        "        box1_x2 = boxes_preds[..., 0:1] + boxes_preds[..., 2:3] / 2\n",
        "        box1_y2 = boxes_preds[..., 1:2] + boxes_preds[..., 3:4] / 2\n",
        "        box2_x1 = boxes_labels[..., 0:1] - boxes_labels[..., 2:3] / 2\n",
        "        box2_y1 = boxes_labels[..., 1:2] - boxes_labels[..., 3:4] / 2\n",
        "        box2_x2 = boxes_labels[..., 0:1] + boxes_labels[..., 2:3] / 2\n",
        "        box2_y2 = boxes_labels[..., 1:2] + boxes_labels[..., 3:4] / 2\n",
        "\n",
        "    if box_format == \"corners\":\n",
        "        box1_x1 = boxes_preds[..., 0:1]\n",
        "        box1_y1 = boxes_preds[..., 1:2]\n",
        "        box1_x2 = boxes_preds[..., 2:3]\n",
        "        box1_y2 = boxes_preds[..., 3:4]\n",
        "        box2_x1 = boxes_labels[..., 0:1]\n",
        "        box2_y1 = boxes_labels[..., 1:2]\n",
        "        box2_x2 = boxes_labels[..., 2:3]\n",
        "        box2_y2 = boxes_labels[..., 3:4]\n",
        "\n",
        "    x1 = torch.max(box1_x1, box2_x1)\n",
        "    y1 = torch.max(box1_y1, box2_y1)\n",
        "    x2 = torch.min(box1_x2, box2_x2)\n",
        "    y2 = torch.min(box1_y2, box2_y2)\n",
        "\n",
        "    intersection = (x2 - x1).clamp(0) * (y2 - y1).clamp(0)\n",
        "    box1_area = abs((box1_x2 - box1_x1) * (box1_y2 - box1_y1))\n",
        "    box2_area = abs((box2_x2 - box2_x1) * (box2_y2 - box2_y1))\n",
        "\n",
        "    return intersection / (box1_area + box2_area - intersection + 1e-6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuxQ22EkRqor"
      },
      "source": [
        "\n",
        "def iou(bboxes1 , bboxes2):\n",
        "    area1 = (bboxes1[..., 2] - bboxes1[..., 0]) * (bboxes1[..., 3] - bboxes1[..., 1])\n",
        "    area2 = (bboxes2[..., 2] - bboxes2[..., 0]) * (bboxes2[..., 3] - bboxes2[..., 1])\n",
        "    inter_max_xy = torch.min(bboxes1[..., 2:],bboxes2[..., 2:])\n",
        "    inter_min_xy = torch.max(bboxes1[..., :2],bboxes2[..., :2])\n",
        "    #print(inter_max_xy.shape , inter_min_xy.shape)\n",
        "    inter = torch.clamp((inter_max_xy - inter_min_xy), min=0)\n",
        "    inter_area = inter[..., 0] * inter[..., 1]\n",
        "    union = area1+area2-inter_area\n",
        "    ious = inter_area / union\n",
        "    ious = torch.clamp(ious,min=0,max = 1.0)\n",
        "    return ious\n",
        "\n",
        "\n",
        "def giou(bboxes1 , bboxes2):\n",
        "    area1 = (bboxes1[..., 2] - bboxes1[..., 0]) * (bboxes1[..., 3] - bboxes1[..., 1])\n",
        "    area2 = (bboxes2[..., 2] - bboxes2[..., 0]) * (bboxes2[..., 3] - bboxes2[..., 1])\n",
        "    inter_max_xy = torch.min(bboxes1[..., 2:],bboxes2[..., 2:])\n",
        "    inter_min_xy = torch.max(bboxes1[..., :2],bboxes2[..., :2])\n",
        "    out_max_xy = torch.max(bboxes1[..., 2:],bboxes2[..., 2:])\n",
        "    out_min_xy = torch.min(bboxes1[..., :2],bboxes2[..., :2])\n",
        "    inter = torch.clamp((inter_max_xy - inter_min_xy), min=0)\n",
        "    inter_area = inter[..., 0] * inter[..., 1]\n",
        "    outer = torch.clamp((out_max_xy - out_min_xy), min=0)\n",
        "    outer_area = outer[..., 0] * outer[..., 1]\n",
        "    union = area1+area2-inter_area\n",
        "    closure = outer_area\n",
        "    ious = inter_area / union - (closure - union) / closure\n",
        "    ious = torch.clamp(ious,min=-1.0,max = 1.0)\n",
        "    return ious\n",
        "\n",
        "def diou(bboxes1 , bboxes2):\n",
        "    w1 = bboxes1[..., 2] - bboxes1[..., 0]\n",
        "    h1 = bboxes1[..., 3] - bboxes1[..., 1]\n",
        "    w2 = bboxes2[..., 2] - bboxes2[..., 0]\n",
        "    h2 = bboxes2[..., 3] - bboxes2[..., 1]\n",
        "\n",
        "    area1 = w1 * h1\n",
        "    area2 = w2 * h2\n",
        "    center_x1 = (bboxes1[..., 2] + bboxes1[..., 0]) / 2\n",
        "    center_y1 = (bboxes1[..., 3] + bboxes1[..., 1]) / 2\n",
        "    center_x2 = (bboxes2[..., 2] + bboxes2[..., 0]) / 2\n",
        "    center_y2 = (bboxes2[..., 3] + bboxes2[..., 1]) / 2\n",
        "\n",
        "    inter_max_xy = torch.min(bboxes1[..., 2:],bboxes2[..., 2:])\n",
        "    inter_min_xy = torch.max(bboxes1[..., :2],bboxes2[..., :2])\n",
        "    out_max_xy = torch.max(bboxes1[..., 2:],bboxes2[..., 2:])\n",
        "    out_min_xy = torch.min(bboxes1[..., :2],bboxes2[..., :2])\n",
        "\n",
        "    inter = torch.clamp((inter_max_xy - inter_min_xy), min=0)\n",
        "    inter_area = inter[..., 0] * inter[..., 1]\n",
        "    inter_diag = (center_x2 - center_x1)**2 + (center_y2 - center_y1)**2\n",
        "    outer = torch.clamp((out_max_xy - out_min_xy), min=0)\n",
        "    outer_diag = (outer[..., 0] ** 2) + (outer[..., 1] ** 2)\n",
        "    union = area1+area2-inter_area\n",
        "    dious = inter_area / union - (inter_diag) / outer_diag\n",
        "    dious = torch.clamp(dious,min=-1.0,max = 1.0)\n",
        "    return dious\n",
        "\n",
        "def ciou(bboxes1 , bboxes2):\n",
        "    w1 = bboxes1[..., 2] - bboxes1[..., 0]\n",
        "    h1 = bboxes1[..., 3] - bboxes1[..., 1]\n",
        "    w2 = bboxes2[..., 2] - bboxes2[..., 0]\n",
        "    h2 = bboxes2[..., 3] - bboxes2[..., 1]\n",
        "\n",
        "    area1 = w1 * h1\n",
        "    area2 = w2 * h2\n",
        "\n",
        "    center_x1 = (bboxes1[..., 2] + bboxes1[..., 0]) / 2\n",
        "    center_y1 = (bboxes1[..., 3] + bboxes1[..., 1]) / 2\n",
        "    center_x2 = (bboxes2[..., 2] + bboxes2[..., 0]) / 2\n",
        "    center_y2 = (bboxes2[..., 3] + bboxes2[..., 1]) / 2\n",
        "\n",
        "    inter_max_xy = torch.min(bboxes1[..., 2:],bboxes2[..., 2:])\n",
        "    inter_min_xy = torch.max(bboxes1[..., :2],bboxes2[..., :2])\n",
        "    out_max_xy = torch.max(bboxes1[..., 2:],bboxes2[..., 2:])\n",
        "    out_min_xy = torch.min(bboxes1[..., :2],bboxes2[..., :2])\n",
        "\n",
        "    inter = torch.clamp((inter_max_xy - inter_min_xy), min=0)\n",
        "    inter_area = inter[..., 0] * inter[..., 1]\n",
        "    inter_diag = (center_x2 - center_x1)**2 + (center_y2 - center_y1)**2\n",
        "    outer = torch.clamp((out_max_xy - out_min_xy), min=0)\n",
        "    outer_diag = (outer[..., 0] ** 2) + (outer[..., 1] ** 2)\n",
        "    union = area1+area2-inter_area\n",
        "    u = (inter_diag) / outer_diag\n",
        "    iou = inter_area / union\n",
        "    v = (4 / (math.pi ** 2)) * torch.pow((torch.atan(w2 / h2) - torch.atan(w1 / h1)), 2)\n",
        "    with torch.no_grad():\n",
        "        S = 1 - iou\n",
        "        alpha = v / (S + v)\n",
        "    cious = iou - (u + alpha * v)\n",
        "    cious = torch.clamp(cious,min=-1.0,max = 1.0)\n",
        "    return cious\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRa6Kkr0GtrX"
      },
      "source": [
        "class Conv(nn.Module):\n",
        "    def __init__(self ,\n",
        "                 in_channels , \n",
        "                 out_channels , \n",
        "                 kernel_size = (3 , 3) , \n",
        "                 stride = (1 , 1) , \n",
        "                 padding = 1 , \n",
        "                 use_norm = True , \n",
        "                 use_activation = True , \n",
        "                 use_pooling = False):\n",
        "        super(Conv , self).__init__()\n",
        "\n",
        "        self.use_norm = use_norm\n",
        "        self.use_activation = use_activation\n",
        "        self.use_pooling = use_pooling\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels , \n",
        "                               out_channels ,\n",
        "                               kernel_size , \n",
        "                               stride , \n",
        "                               padding)\n",
        "        if self.use_norm:\n",
        "            self.norm = nn.InstanceNorm2d(out_channels)\n",
        "        if self.use_activation:\n",
        "            self.activation = nn.Mish()\n",
        "\n",
        "        if self.use_pooling:\n",
        "            self.pooling = nn.MaxPool2d(kernel_size=(2 , 2) , stride=(2 , 2))\n",
        "\n",
        "    def forward(self , x):\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        if self.use_norm:\n",
        "            x = self.norm(x)\n",
        "        if self.use_activation:\n",
        "            x = self.activation(x)\n",
        "        if self.use_pooling:\n",
        "            x = self.pooling(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzmFNusEHih3"
      },
      "source": [
        "class ConvT(nn.Module):\n",
        "    def __init__(self , \n",
        "                 in_channels , \n",
        "                 out_channels , \n",
        "                 kernel_size = (2 , 2) , \n",
        "                 stride = (2 , 2) , \n",
        "                 padding = 0 , \n",
        "                 use_norm = True , \n",
        "                 use_activation = True):\n",
        "        super(ConvT , self).__init__()\n",
        "\n",
        "        self.use_norm = use_norm\n",
        "        self.use_activation = use_activation\n",
        "\n",
        "        self.convT = nn.ConvTranspose2d(in_channels , \n",
        "                                        out_channels , \n",
        "                                        kernel_size , \n",
        "                                        stride ,\n",
        "                                        padding)\n",
        "        if self.use_norm:\n",
        "            self.norm = nn.InstanceNorm2d(out_channels)\n",
        "        if self.use_activation:\n",
        "            self.activation = nn.Mish()\n",
        "\n",
        "    def forward(self , x):\n",
        "        x = self.convT(x)\n",
        "        if self.use_norm:\n",
        "            x = self.norm(x)\n",
        "        if self.use_activation:\n",
        "            x = self.activation(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUCTBzMNGwh4"
      },
      "source": [
        "class Darknet_Conv(nn.Module):\n",
        "    def __init__(self ,\n",
        "                 in_channels , \n",
        "                 out_channels):\n",
        "        super(Darknet_Conv , self).__init__()\n",
        "\n",
        "        self.conv1 = Conv(in_channels , \n",
        "                          in_channels , \n",
        "                          kernel_size = (1 , 1) , \n",
        "                          stride = (1 , 1) , \n",
        "                          padding = 0)\n",
        "        self.conv2 = Conv(in_channels , in_channels)\n",
        "        self.conv3 = Conv(in_channels , \n",
        "                          out_channels , \n",
        "                          kernel_size=(1 , 1) , \n",
        "                          stride = (1 ,1 ) , \n",
        "                          padding = 0)\n",
        "\n",
        "    def forward(self , x):\n",
        "        x_ = x.clone()\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x += x_\n",
        "        x = self.conv3(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwD55Zd6Imcr"
      },
      "source": [
        "class CAM(nn.Module):\n",
        "    ## Channel Attention Module\n",
        "    def __init__(self , \n",
        "                 in_channels , \n",
        "                 r=1):\n",
        "        super(CAM , self).__init__()\n",
        "\n",
        "        self.adp_max_pool = nn.AdaptiveMaxPool2d(output_size=(1 , 1))\n",
        "        self.adp_avg_pool = nn.AdaptiveAvgPool2d(output_size=(1 , 1))\n",
        "        self.linear = nn.Linear(in_channels , in_channels//r)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self , x):\n",
        "        x_max = self.adp_max_pool(x)\n",
        "        x_avg = self.adp_avg_pool(x)\n",
        "        #print(x_max.shape , x_avg.shape)\n",
        "        x_max = self.linear(x_max.squeeze(-1).squeeze(-1))\n",
        "        x_avg = self.linear(x_avg.squeeze(-1).squeeze(-1))\n",
        "\n",
        "        x = x_max + x_avg\n",
        "        x = self.sigmoid(x)\n",
        "        return x.view(x.shape[0] , x.shape[1] , 1 , 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqkcgQgyIpf8"
      },
      "source": [
        "class SAM(nn.Module):\n",
        "    ## Spatial Attention Module\n",
        "    def __init__(self , \n",
        "                 in_channels):\n",
        "        super(SAM , self).__init__()\n",
        "\n",
        "        self.conv1 = Conv(in_channels , 1 , kernel_size=(1 , 1) , stride=(1 , 1) , padding=0)\n",
        "\n",
        "        self.conv2 = Conv(1 , in_channels//2)\n",
        "        self.conv3 = Conv(in_channels//2 , 1)\n",
        "    def forward(self , x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Te_zo_vjIsM6"
      },
      "source": [
        "class CBAM(nn.Module):\n",
        "    def __init__(self , \n",
        "                 in_channels):\n",
        "        super(CBAM , self).__init__()\n",
        "\n",
        "        self.sam = SAM(in_channels)\n",
        "        self.cam = CAM(in_channels)\n",
        "\n",
        "    def forward(self , x):\n",
        "        x_ = x.clone()\n",
        "        x = self.cam(x)\n",
        "        x = x_ * x\n",
        "        x = self.sam(x)\n",
        "        x = x_ * x\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UE9eBFFxGzfX"
      },
      "source": [
        "class DenseNet_Block(nn.Module):\n",
        "    def __init__(self , \n",
        "                 in_channels , \n",
        "                 repeats , \n",
        "                 k = 12):\n",
        "        super(DenseNet_Block , self).__init__()\n",
        "\n",
        "        self.layers = nn.ModuleList()\n",
        "        out_channels_last = 0\n",
        "        in_channels_conv = in_channels // 3\n",
        "        self.remaining_in_channels = in_channels - in_channels_conv\n",
        "\n",
        "        self.in_channels_ = in_channels\n",
        "        self.in_channels_conv_ = in_channels_conv\n",
        "        for r in range(repeats):\n",
        "            #in_channels = in_channels + out_channels_last\n",
        "            out_channels = in_channels_conv + k \n",
        "            #print(in_channels , out_channels)\n",
        "            self.layers.append(Darknet_Conv(in_channels_conv , \n",
        "                                             out_channels))\n",
        "            self.layers.append(CBAM(out_channels))\n",
        "            \n",
        "            out_channels_last += in_channels_conv\n",
        "            in_channels_conv = out_channels + out_channels_last\n",
        "        #print(out_channels)\n",
        "        self.out_channels = out_channels + self.remaining_in_channels+ out_channels_last\n",
        "\n",
        "        \n",
        "    def _concat(self , x , prev):\n",
        "        for prev_ in prev:\n",
        "            x = torch.cat([x , prev_] , dim=1)\n",
        "        return x\n",
        "\n",
        "    def forward(self , x):\n",
        "        x_cpy = x.clone()\n",
        "        x = x[: , :self.in_channels_conv_ , : , :]\n",
        "        x_ = x_cpy[: , self.in_channels_conv_ : self.in_channels_ , : , :]\n",
        "        #print(x_.shape)\n",
        "        prev = [x]\n",
        "        for layer in self.layers:\n",
        "            #print(x.shape)\n",
        "            x = layer(x)\n",
        "            x = self._concat(x , prev)\n",
        "            prev.append(x)\n",
        "        #print(x.shape , x_.shape)\n",
        "        x = torch.cat([x , x_] , dim=1)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byTHroUgG3Ln"
      },
      "source": [
        "config = [\n",
        "          [64 , (3 , 3) , (1 , 1) , 1 , True , True , True] ,  # [out_channels , kernel_size , stride , padding , norm , activation , pooling]\n",
        "          1 , \n",
        "          [128 , (3 , 3) , (1 , 1) , 1 , True , True , True] , \n",
        "          2 , \n",
        "          [256 , (3 , 3) , (1 , 1) , 1 , True , True , True] , \n",
        "          8 , \n",
        "          [512 , (3 , 3) , (1 , 1) , 1 , True , True , True] , \n",
        "          8 , \n",
        "          [1024 , (3 , 3) , (1 , 1) , 1 , True , True , True] , \n",
        "          4\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpQTqPbgG7XP"
      },
      "source": [
        "class CSPDarknet(nn.Module):\n",
        "    def __init__(self , \n",
        "                 in_channels , \n",
        "                 config = config):\n",
        "        super(CSPDarknet , self).__init__()\n",
        "\n",
        "        self.layers = nn.ModuleList()\n",
        "        out_channels_list = [64 , 128 , 256 , 512 , 1024]\n",
        "        i = 0\n",
        "        for  layer in config:\n",
        "            if isinstance(layer , list):\n",
        "                out_channels , kernel_size , stride , padding , use_norm , use_activation , use_padding = layer\n",
        "                self.layers.append(Conv(in_channels , out_channels , kernel_size , stride , padding , use_norm , use_activation , use_padding))\n",
        "                in_channels = out_channels\n",
        "\n",
        "            elif isinstance(layer , int):\n",
        "                repeats = layer\n",
        "                a = DenseNet_Block(in_channels , repeats)\n",
        "                self.layers.append(a)\n",
        "                in_channels = a.out_channels\n",
        "                out_channels = out_channels_list[i]\n",
        "                self.layers.append(Conv(in_channels , out_channels , kernel_size=(1 , 1) , stride=(1 , 1) , padding=0))\n",
        "                i += 1\n",
        "                in_channels = out_channels\n",
        "\n",
        "                \n",
        "    def forward(self , x):\n",
        "        layer_out = []\n",
        "        for i , layer in enumerate(self.layers):\n",
        "            x = layer(x)\n",
        "            if i != 0 :\n",
        "                layer_out.append(x)\n",
        "        return layer_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4bOvZy-HuTN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "e7626c1f-fc87-488e-846e-4bb47d02e25a"
      },
      "source": [
        "'''cspdensenet = CSPDarknet(3).to(device)\n",
        "x = torch.randn(2 , 3 , 416 , 416).to(device)\n",
        "z = cspdensenet(x)\n",
        "for data in z:\n",
        "    print(data.shape)'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cspdensenet = CSPDarknet(3).to(device)\\nx = torch.randn(2 , 3 , 416 , 416).to(device)\\nz = cspdensenet(x)\\nfor data in z:\\n    print(data.shape)'"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aolQBH5xHIl_"
      },
      "source": [
        "class PAN_Net(nn.Module):\n",
        "    def __init__(self , \n",
        "                 in_channels = [2048 , 1024 , 512 , 256] ,\n",
        "                 out_channels = [128 , 256 , 512 , 1024]):\n",
        "        super(PAN_Net , self).__init__()\n",
        "\n",
        "        self.top_down = nn.ModuleList()\n",
        "        self.bottom_up = nn.ModuleList()\n",
        "        \n",
        "        for i , channel in enumerate(in_channels):\n",
        "            if i > 2 and i != len(in_channels) -1:\n",
        "                channel = channel + in_channels[i-1]\n",
        "            out_channel = channel // 2\n",
        "            self.top_down.append(ConvT(channel , out_channel))\n",
        "            #channel = out_channel\n",
        "        \n",
        "        for i , channel in enumerate(out_channels):\n",
        "            if i > 2 and i!= len(out_channels)-1 :\n",
        "                channel = channel * 2 \n",
        "            out_channel = out_channels[i] * 2\n",
        "            self.bottom_up.append(Conv(channel , out_channel , use_pool=True))\n",
        "\n",
        "        #print(self.bottom_up)\n",
        "    def forward(self , x):\n",
        "        p = [x[0]]\n",
        "        N = []\n",
        "        x0 , x1 , x2 , x3 = x\n",
        "        for i , layer in enumerate(self.top_down):\n",
        "            if i > 2 and i!= len(self.top_down)-1:\n",
        "                #p[i] = p[i] + x[i+1]\n",
        "                #print(i , len(p) , len(x))\n",
        "                p[i] = torch.cat([p[i] , x[i]] , dim=1)\n",
        "            #print(p[i].shape)\n",
        "            p.append(layer(p[i]))\n",
        "            #print(p[i].shape)\n",
        "\n",
        "        p_ = Reverse(p)\n",
        "        N.append(p_[0])\n",
        "        for i , layer in enumerate(self.bottom_up):\n",
        "            if i > 2 and i!= len(self.top_down)-1:\n",
        "                #N[i] = N[i] + p_[i+1]\n",
        "                N[i] = torch.cat([N[i] , p_[i]] , dim=1)\n",
        "            #print(N[i].shape)\n",
        "            N.append(layer(N[i]))\n",
        "            #print(N[i].shape)\n",
        "        return N[1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWAU5Z2jKJey"
      },
      "source": [
        "class Residual_Block(nn.Module):\n",
        "    def __init__(self , \n",
        "                 in_channels , \n",
        "                 num_repeats , \n",
        "                 residual = True):\n",
        "        super(Residual_Block , self).__init__()\n",
        "\n",
        "        self.residual = residual\n",
        "        self.num_repeats = num_repeats\n",
        "        layers = []\n",
        "\n",
        "\n",
        "        for repeat in range(self.num_repeats):\n",
        "            layers.append(Conv(\n",
        "                in_channels , \n",
        "                in_channels // 2 ,\n",
        "                kernel_size = (1 , 1) , \n",
        "                stride = (1 , 1) , \n",
        "                padding = 0\n",
        "            ))\n",
        "\n",
        "            layers.append(Conv(\n",
        "                in_channels //2 , \n",
        "                in_channels\n",
        "            ))\n",
        "\n",
        "        self.conv = nn.Sequential(*layers)\n",
        "    def forward(self , x):\n",
        "        if self.residual:\n",
        "            x_ = self.conv(x)\n",
        "            x = x + x_\n",
        "            return x\n",
        "        else:\n",
        "            x = self.conv(x)\n",
        "            return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSjOmYXdKRTE"
      },
      "source": [
        "class Scaled_Predictions(nn.Module):\n",
        "    def __init__(self , \n",
        "                 in_channels , \n",
        "                 out_channels , \n",
        "                 B = 3):\n",
        "        super(Scaled_Predictions , self).__init__()\n",
        "        self.B = B\n",
        "        self.out_channels = out_channels\n",
        "        self.conv1 = Conv(in_channels , in_channels * 2 )\n",
        "        self.conv2 = Conv(in_channels * 2 , (self.out_channels + 5) * B , use_norm=False , use_activation=False)\n",
        "\n",
        "    def forward(self , x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = x.view(x.shape[0] , self.B , x.shape[2] , x.shape[3] , self.out_channels + 5 )\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU3u7klWHOAt"
      },
      "source": [
        "class YOLO_v3(nn.Module):\n",
        "    def __init__(self , \n",
        "                 in_channels , \n",
        "                 out_channels = 20):\n",
        "        super(YOLO_v3 , self).__init__()\n",
        "\n",
        "        self.residual_block = Residual_Block(in_channels , 1 , False)\n",
        "        self.conv1 = Conv(in_channels , in_channels // 2 , kernel_size=(1 , 1) , stride=(1 , 1) , padding=0)\n",
        "        self.scaled_pred = Scaled_Predictions(in_channels//2 , out_channels)\n",
        "\n",
        "    def forward(self , x):\n",
        "        x = self.residual_block(x)\n",
        "        x = self.conv1(x)\n",
        "        x = self.scaled_pred(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIh7HKu0K_1k"
      },
      "source": [
        "class YOLO_v4(nn.Module):\n",
        "    def __init__(self , \n",
        "                 in_channels = 3):\n",
        "        super(YOLO_v4 , self).__init__()\n",
        "\n",
        "        out_channels_list = [128 , 256 , 512 , 1024]\n",
        "\n",
        "        self.yolo_v3_layers = nn.ModuleList()\n",
        "        self.csp_darknet = CSPDarknet(in_channels)\n",
        "        self.pannet = PAN_Net()\n",
        "        \n",
        "        for i in out_channels_list:\n",
        "            self.yolo_v3_layers.append(\n",
        "                YOLO_v3(i)\n",
        "            )\n",
        "    \n",
        "    def forward(self , x):\n",
        "        out = []\n",
        "        x = self.csp_darknet(x)\n",
        "        x = self.pannet(x)\n",
        "\n",
        "        for i , x_ in enumerate(x):\n",
        "            y = self.yolo_v3_layers[i](x_)\n",
        "            out.append(y)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LI5wW8JCM8Zg"
      },
      "source": [
        "anchors = [\n",
        "    [(0.28, 0.22), (0.38, 0.48), (0.9, 0.78)],\n",
        "    [(0.07, 0.15), (0.15, 0.11), (0.14, 0.29)],\n",
        "    [(0.02, 0.03), (0.04, 0.07), (0.08, 0.06)],\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNsP6WawNECv"
      },
      "source": [
        "class Dataset_(torch.utils.data.Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        csv_file,\n",
        "        img_dir,\n",
        "        label_dir,\n",
        "        anchors = anchors,\n",
        "        S=[13, 26, 52 , 104],\n",
        "        C=20,\n",
        "        transform=None,\n",
        "    ):\n",
        "        self.df = pd.read_csv(csv_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.label_dir = label_dir\n",
        "        self.transform = transform\n",
        "        self.S = S\n",
        "        self.anchors = torch.tensor(anchors[0] + anchors[1] + anchors[2])\n",
        "        self.num_anchors = self.anchors.shape[0]\n",
        "        self.num_anchors_per_scale = self.num_anchors // 3\n",
        "        self.C = C\n",
        "        self.ignore_iou_thresh = 0.5\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self , idx):\n",
        "        label_path = os.path.join(self.label_dir , self.df.iloc[idx , 1])\n",
        "        boxes = []\n",
        "\n",
        "        with open(label_path) as f:\n",
        "            for label in f.readlines():\n",
        "                class_label , x , y , width , height = [\n",
        "                    float(x) if float(x) != int(float(x)) else int(x)\n",
        "                    for x in label.replace(\"\\n\", \"\").split()\n",
        "                ]\n",
        "                boxes.append([ x , y , width , height , class_label])\n",
        "\n",
        "        boxes = torch.tensor(boxes) \n",
        "\n",
        "        image_path = os.path.join(self.img_dir , self.df.iloc[idx , 0])\n",
        "        image = np.asarray(plt.imread(image_path))\n",
        "        image = torch.from_numpy(image).permute(2 , 0 , 1)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        target = [torch.zeros((self.num_anchors // 3 , S , S , 25)) for S in self.S]\n",
        "\n",
        "        for box in boxes:\n",
        "            iou_anchors = iou_width_height(box[2:4] , self.anchors)\n",
        "            anchors_indices = iou_anchors.argsort(descending = True , dim = 0)\n",
        "\n",
        "            x , y , width , height , class_label = box\n",
        "            has_anchor = [False] * 3\n",
        "            for anchor_idx in anchors_indices:\n",
        "                scale_idx = anchor_idx // self.num_anchors_per_scale\n",
        "                anchor_on_scale = anchor_idx % self.num_anchors_per_scale\n",
        "                S = self.S[scale_idx]\n",
        "                i , j = int(S * y) , int(S * x)\n",
        "                anchor_taken = target[scale_idx][anchor_on_scale , i , j , 0]\n",
        "                if not anchor_taken and not has_anchor[scale_idx] :\n",
        "                    target[scale_idx][anchor_on_scale, i , j , 0] = 1\n",
        "                    x_cell , y_cell = S * x - j , S * y - i\n",
        "                    width_cell , height_cell = (\n",
        "                        width * S , \n",
        "                        height * S\n",
        "                    )\n",
        "                    box_coordinates = torch.tensor(\n",
        "                        [x_cell , y_cell , width_cell , height_cell]\n",
        "                    )\n",
        "                    target[scale_idx][anchor_on_scale , i , j , 1:5] = box_coordinates\n",
        "                    target[scale_idx][anchor_on_scale , i , j , 5] = int(class_label)\n",
        "                    has_anchor[scale_idx] = True\n",
        "\n",
        "                elif not anchor_taken and iou_anchors[anchor_idx] > self.ignore_iou_thresh:\n",
        "                    target[scale_idx][anchor_on_scale , i , j , 0] = -1\n",
        "        return image , tuple(target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yEEcm_INMrf"
      },
      "source": [
        "transform = transforms.Compose([\n",
        "                                transforms.ToPILImage() , \n",
        "                                transforms.Resize((416 , 416)) , \n",
        "                                transforms.ToTensor()\n",
        "])\n",
        "dataset = Dataset_(\n",
        "    img_dir = '/content/drive/MyDrive/Yolo_Dataset/images/' , \n",
        "    label_dir = '/content/drive/MyDrive/Yolo_Dataset/labels' , \n",
        "    csv_file = '/content/drive/MyDrive/Yolo_Dataset/train.csv' , \n",
        "    transform = transform\n",
        ")\n",
        "dataloader = torch.utils.data.DataLoader(dataset , batch_size = 1 , shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_me6YyLNP5f"
      },
      "source": [
        "for x , y in dataloader:\n",
        "    show_tensor_images(x)\n",
        "    for data in y:\n",
        "        print(data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rf7Ds7q5Rfxn"
      },
      "source": [
        "class IOU_Loss(nn.Module):\n",
        "    def __init__(self , \n",
        "                 loss_type = 'iou'): ## loss types are [iou , giou , diou , ciou]\n",
        "        super(IOU_Loss , self).__init__()\n",
        "\n",
        "        self.loss_type = loss_type\n",
        "\n",
        "    def forward(self , pred_box , trg_box):\n",
        "        if self.loss_type == 'iou':\n",
        "            loss = torch.sum(1.0 - iou(pred_box , trg_box))\n",
        "        else :\n",
        "            if self.loss_type == 'giou':\n",
        "                loss = torch.sum(1.0 - giou(pred_box , trg_box))\n",
        "            else:\n",
        "                if self.loss_type == 'diou':\n",
        "                    loss = torch.sum(1.0 - diou(pred_box , trg_box))\n",
        "                else:\n",
        "                    loss = torch.sum(1.0 - ciou(pred_box , trg_box))\n",
        "        return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxZr6Dh-R4k2"
      },
      "source": [
        "yolo_v4 = YOLO_v4().to(device)\n",
        "lr = 0.002\n",
        "betas = (0.5 , 0.999)\n",
        "opt = torch.optim.Adam(yolo.parameters() , lr=lr , betas = betas)\n",
        "epochs = 200\n",
        "display_steps = 1\n",
        "l1_criterion = nn.L1Loss()\n",
        "loss_fn = IOU_Loss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2JcqJnkSIcj"
      },
      "source": [
        "def train():\n",
        "    mean_yolo_loss = 0\n",
        "    cur_step = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for x , y in tqdm(dataloader):\n",
        "            x = x.to(device)\n",
        "            y0, y1, y2 , y3 = (\n",
        "                y[0].to(device),\n",
        "                y[1].to(device),\n",
        "                y[2].to(device),\n",
        "                y[3].to(device))\n",
        "\n",
        "            opt.zero_grad()\n",
        "            out = yolo_v4(x)\n",
        "            loss = (\n",
        "                loss_fn(out[0][... , :4].squeeze(0), y0[... , :4].squeeze(0))\n",
        "                + loss_fn(out[1][... , :4].squeeze(0), y1[... , :4].squeeze(0))\n",
        "                + loss_fn(out[2][... , :4].squeeze(0), y2[... , :4].squeeze(0))\n",
        "                + loss_fn(out[3][... , :4].squeeze(0), y3[... , :4].squeeze(0))\n",
        "            )\n",
        "            loss_classes = (\n",
        "                l1_criterion(out[0][... , 5:].squeeze(0) , y0[... , 5:].squeeze(0)\n",
        "                             + l1_criterion(out[1][... , 5:].squeeze(0) , y1[... , 5:].squeeze(0))\n",
        "                             + l1_criterion(out[2][... , 5:].squeeze(0) , y2[... , 5:].squeeze(0)))\n",
        "                             + l1_criterion(out[3][... , 5:].squeeze(0) , y3[... , 5:].squeeze(0)))\n",
        "            )\n",
        "            loss += loss_classes\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            \n",
        "            mean_yolo_loss += loss.item() / display_steps\n",
        "            if cur_step % display_steps == 0:\n",
        "                print(f'Epoch {epoch} , Step {cur_step} , Mean YOLO Loss {mean_yolo_loss}')\n",
        "            cur_step +=1\n",
        "        mean_yolo_loss = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIjDaycMcAj8"
      },
      "source": [
        "train()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}