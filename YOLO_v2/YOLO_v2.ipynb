{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 275,
      "metadata": {
        "id": "UXSv4rR5OlXC"
      },
      "outputs": [],
      "source": [
        "####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 318,
      "metadata": {
        "id": "sV77Jh8sPWe-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision import transforms\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "metadata": {
        "id": "VeIWv9lySH5d"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 278,
      "metadata": {
        "id": "lIKB2ST_KkZI"
      },
      "outputs": [],
      "source": [
        "def show_tensor_images(image_tensor, num_images=2, size=(3 , 416 , 416)):\n",
        "    image_shifted = image_tensor\n",
        "    image_unflat = image_shifted.detach().cpu().view(-1, *size)\n",
        "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
        "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 279,
      "metadata": {
        "id": "WNrdouGP0_ft"
      },
      "outputs": [],
      "source": [
        "def iou_width_height(boxes1, boxes2):\n",
        "\n",
        "    intersection = torch.min(boxes1[..., 0], boxes2[..., 0]) * torch.min(\n",
        "        boxes1[..., 1], boxes2[..., 1]\n",
        "    )\n",
        "    union = (\n",
        "        boxes1[..., 0] * boxes1[..., 1] + boxes2[..., 0] * boxes2[..., 1] - intersection\n",
        "    )\n",
        "    return intersection / union"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 280,
      "metadata": {
        "id": "JuOeB2Ea0EmY"
      },
      "outputs": [],
      "source": [
        "def intersection_over_union(boxes_preds, boxes_labels, box_format=\"midpoint\"):\n",
        "\n",
        "    if box_format == \"midpoint\":\n",
        "        box1_x1 = boxes_preds[..., 0:1] - boxes_preds[..., 2:3] / 2\n",
        "        box1_y1 = boxes_preds[..., 1:2] - boxes_preds[..., 3:4] / 2\n",
        "        box1_x2 = boxes_preds[..., 0:1] + boxes_preds[..., 2:3] / 2\n",
        "        box1_y2 = boxes_preds[..., 1:2] + boxes_preds[..., 3:4] / 2\n",
        "        box2_x1 = boxes_labels[..., 0:1] - boxes_labels[..., 2:3] / 2\n",
        "        box2_y1 = boxes_labels[..., 1:2] - boxes_labels[..., 3:4] / 2\n",
        "        box2_x2 = boxes_labels[..., 0:1] + boxes_labels[..., 2:3] / 2\n",
        "        box2_y2 = boxes_labels[..., 1:2] + boxes_labels[..., 3:4] / 2\n",
        "\n",
        "    if box_format == \"corners\":\n",
        "        box1_x1 = boxes_preds[..., 0:1]\n",
        "        box1_y1 = boxes_preds[..., 1:2]\n",
        "        box1_x2 = boxes_preds[..., 2:3]\n",
        "        box1_y2 = boxes_preds[..., 3:4]\n",
        "        box2_x1 = boxes_labels[..., 0:1]\n",
        "        box2_y1 = boxes_labels[..., 1:2]\n",
        "        box2_x2 = boxes_labels[..., 2:3]\n",
        "        box2_y2 = boxes_labels[..., 3:4]\n",
        "\n",
        "    x1 = torch.max(box1_x1, box2_x1)\n",
        "    y1 = torch.max(box1_y1, box2_y1)\n",
        "    x2 = torch.min(box1_x2, box2_x2)\n",
        "    y2 = torch.min(box1_y2, box2_y2)\n",
        "\n",
        "    intersection = (x2 - x1).clamp(0) * (y2 - y1).clamp(0)\n",
        "    box1_area = abs((box1_x2 - box1_x1) * (box1_y2 - box1_y1))\n",
        "    box2_area = abs((box2_x2 - box2_x1) * (box2_y2 - box2_y1))\n",
        "\n",
        "    return intersection / (box1_area + box2_area - intersection + 1e-6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 281,
      "metadata": {
        "id": "unoFZvV5Pj4s"
      },
      "outputs": [],
      "source": [
        "class Conv(nn.Module):\n",
        "    def __init__(self , \n",
        "                 in_channels , \n",
        "                 out_channels , \n",
        "                 kernel_size = (3 , 3) , \n",
        "                 stride = (1 , 1) , \n",
        "                 padding = 1 , \n",
        "                 use_norm = True , \n",
        "                 use_activation = True , \n",
        "                 use_pool = True):\n",
        "        super(Conv , self).__init__()\n",
        "\n",
        "        self.use_norm = use_norm\n",
        "        self.use_activation = use_activation\n",
        "        self.use_pool = use_pool\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels , \n",
        "                               out_channels , \n",
        "                               kernel_size , \n",
        "                               stride , \n",
        "                               padding)\n",
        "        if self.use_norm:\n",
        "            self.norm = nn.BatchNorm2d(out_channels)\n",
        "        if self.use_activation:\n",
        "            self.activation = nn.LeakyReLU(0.2)\n",
        "        if self.use_pool:\n",
        "            self.maxpool = nn.MaxPool2d(kernel_size=2 , stride=2)\n",
        "    def forward(self , x):\n",
        "        x = self.conv1(x)\n",
        "        if self.use_norm:\n",
        "            x = self.norm(x)\n",
        "        if self.use_activation:\n",
        "            x = self.activation(x)\n",
        "        if self.use_pool:\n",
        "            x = self.maxpool(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlTeqolyQS3n"
      },
      "outputs": [],
      "source": [
        "x = torch.randn(2 , 3 , 512 , 512).to(device)\n",
        "conv = Conv(3 , 32).to(device)\n",
        "z = conv(x)\n",
        "z.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 283,
      "metadata": {
        "id": "dhnhVw7wk-vd"
      },
      "outputs": [],
      "source": [
        "class ReOrgLayer(nn.Module):\n",
        "    def __init__(self, stride = 2):\n",
        "        super(ReOrgLayer, self).__init__()\n",
        "        self.stride= stride\n",
        "        \n",
        "    def forward(self,x):\n",
        "        assert(x.data.dim() == 4)\n",
        "        B,C,H,W = x.data.shape\n",
        "        hs = self.stride\n",
        "        ws = self.stride\n",
        "        assert(H % hs == 0),  \"The stride \" + str(self.stride) + \" is not a proper divisor of height \" + str(H)\n",
        "        assert(W % ws == 0),  \"The stride \" + str(self.stride) + \" is not a proper divisor of height \" + str(W)\n",
        "        x = x.view(B,C, H // hs, hs, W // ws, ws).transpose(-2,-3).contiguous()\n",
        "        x = x.view(B,C, H // hs * W // ws, hs, ws)\n",
        "        x = x.view(B,C, H // hs * W // ws, hs*ws).transpose(-1,-2).contiguous()\n",
        "        x = x.view(B, C, ws*hs, H // ws, W // ws).transpose(1,2).contiguous()\n",
        "        x = x.view(B, C*ws*hs, H // ws, W // ws)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 284,
      "metadata": {
        "id": "dXG_HxQPSFk8"
      },
      "outputs": [],
      "source": [
        "config = [\n",
        "          #[out_channels , kernel_size , stride , padding , maxpool]\n",
        "          # List for Conv and maxpool\n",
        "          # Tuple for Conv3x3 , Conv1x1 , Conv3x3\n",
        "            [32 , 3 , 1 , 1 , 1] , \n",
        "            [64 , 3 , 1 , 1 , 1] , \n",
        "            128 , # (out_channels = 128 , kernel_size = 3 , stride = 1 , padding = 1)\n",
        "                    # (out_channels = 64 , kernel_size = 1 , stride = 1 , padding = 0)\n",
        "                    # (out_channels = 128 , kernel_size = 3 , stride = 1 , padding = 0)\n",
        "            'M' , \n",
        "            256 , \n",
        "            'M' , \n",
        "            512 , \n",
        "            [256 , 1 , 1 , 0 , 0] ,\n",
        "            ('S' , [512 , 3 , 1 , 1 , 0]) , ## Tuple and S => to save results \n",
        "                                            ## and to use it for skip connections and use reorganize\n",
        "            'M' , # Maxpool\n",
        "            1024 , \n",
        "            [512 , 1 , 1 , 0 , 0] , \n",
        "            [1024 , 3 , 1 , 1 , 0] ,\n",
        "            [1024 , 3 , 1 , 1 , 0] , \n",
        "            [1024 , 3 , 1 , 1 , 0] ,  \n",
        "            'C' , # Concat with skip connections dim = 1\n",
        "            ('add' , [1024 , 3 , 1 , 1 , 0]) , \n",
        "            [125 , 1 , 1 , 0 , 0] \n",
        "\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 285,
      "metadata": {
        "id": "Q7n6VKJVwKFJ"
      },
      "outputs": [],
      "source": [
        "class Support(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Support , self).__init__()\n",
        "\n",
        "        self.in_channels = 3\n",
        "    def forward(self , x):\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 286,
      "metadata": {
        "id": "RfW6zLQPw2ec"
      },
      "outputs": [],
      "source": [
        "class Support_(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Support_ , self).__init__()\n",
        "\n",
        "        self.in_channels = 3\n",
        "    def forward(self , x):\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 287,
      "metadata": {
        "id": "Uf3eVc0YMQzI"
      },
      "outputs": [],
      "source": [
        "B = 5\n",
        "S = 13\n",
        "C = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 288,
      "metadata": {
        "id": "E8e6dLJMcXmn"
      },
      "outputs": [],
      "source": [
        "class YOLO(nn.Module):\n",
        "    def __init__(self , \n",
        "                 in_channels = 3 ,\n",
        "                 config = config , \n",
        "                 B = B , \n",
        "                 C = C , \n",
        "                 S = S):\n",
        "        super(YOLO , self).__init__()\n",
        "\n",
        "        self.layers = nn.ModuleList()\n",
        "        self.config = config\n",
        "        self.B = B\n",
        "        self.C = C \n",
        "        self.S = S\n",
        "        for module in self.config:\n",
        "            if isinstance(module , list):\n",
        "                out_channels , kernel_size , stride , padding , use_pool = module\n",
        "                use_pool = True if use_pool == 1 else False\n",
        "                self.layers.append(Conv(\n",
        "                    in_channels , out_channels , kernel_size , stride , padding , use_pool=use_pool\n",
        "                ))\n",
        "                in_channels = out_channels\n",
        "            \n",
        "            elif isinstance(module , int):\n",
        "                out_channels = module\n",
        "                self.layers.append(\n",
        "                    Conv(in_channels, out_channels , use_pool=False))\n",
        "                self.layers.append(\n",
        "                    Conv(out_channels , out_channels //2 , kernel_size=(1 , 1) , stride=(1 , 1) , padding=0 , use_pool=False)\n",
        "                )\n",
        "                self.layers.append(\n",
        "                    Conv(out_channels // 2 , in_channels * 2 , use_pool=False)\n",
        "                )\n",
        "                in_channels = out_channels\n",
        "            \n",
        "            elif isinstance(module , tuple) and module[0] == 'S':\n",
        "                out_channels , kernel_size , stride , padding , use_pool = module[1]\n",
        "                use_pool = True if use_pool == 1 else False\n",
        "                #self.layers.append(nn.Identity())\n",
        "                self.layers.append(Conv(\n",
        "                    in_channels , out_channels , kernel_size , stride , padding , use_pool = use_pool\n",
        "                ))\n",
        "                self.layers.append(Support())\n",
        "                in_channels = out_channels\n",
        "            \n",
        "            elif isinstance(module , str) and module == 'M':\n",
        "                self.layers.append(nn.MaxPool2d(kernel_size=2 , stride=2))\n",
        "        \n",
        "            elif isinstance(module , tuple) and module[0] == 'add':\n",
        "                out_channels , kernel_size , stride , padding , use_pool = module[1]\n",
        "                use_pool = True if use_pool == 1 else False\n",
        "                self.layers.append(Conv(\n",
        "                    3072 , out_channels , kernel_size , stride , padding , use_pool = use_pool\n",
        "                ))\n",
        "                in_channels = out_channels\n",
        "\n",
        "            elif isinstance(module , str) and module == 'C':\n",
        "                self.layers.append(Support_())\n",
        "        self.reorg_layer = ReOrgLayer()\n",
        "\n",
        "    \n",
        "    def forward(self , x):\n",
        "        for_save = []\n",
        "        for layer in self.layers:\n",
        "            if isinstance(layer , Support):\n",
        "                x = layer(x)\n",
        "                for_save.append(x)\n",
        "            elif isinstance(layer , Support_):\n",
        "                x_ = self.reorg_layer(for_save[-1])\n",
        "                x = torch.cat([x , x_] , dim=1)\n",
        "            else:\n",
        "                x = layer(x)\n",
        "        return x.view(x.shape[0] , self.B , self.S , self.S , self.C + 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5OJ6eiogfd5"
      },
      "outputs": [],
      "source": [
        "yolo = YOLO().to(device)\n",
        "x = torch.randn(2,  3 , 416 , 416)\n",
        "z = yolo(x)\n",
        "z.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 331,
      "metadata": {
        "id": "eQvnA2LVvm4x"
      },
      "outputs": [],
      "source": [
        "class Dataset_(torch.utils.data.Dataset):\r\n",
        "    def __init__(self ,\r\n",
        "                 img_dir , \r\n",
        "                 label_dir , \r\n",
        "                 csv_file , \r\n",
        "                 anchors , \r\n",
        "                 transforms = None , \r\n",
        "                 S = 13 , \r\n",
        "                 B = 5 , \r\n",
        "                 C = 20 ):\r\n",
        "        super(Dataset_ , self).__init__()\r\n",
        "\r\n",
        "        self.img_dir = img_dir\r\n",
        "        self.label_dir = label_dir\r\n",
        "        self.df = pd.read_csv(csv_file)\r\n",
        "        self.anchors = torch.from_numpy(np.array(anchors))\r\n",
        "        #print(self.anchors)\r\n",
        "        self.transforms = transforms\r\n",
        "        self.number_of_anchors_per_cell = 5\r\n",
        "        self.ignore_iou_thresh = 0.5\r\n",
        "        self.C = C\r\n",
        "        self.S = S\r\n",
        "        self.B = B\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.df)\r\n",
        "    \r\n",
        "    def __getitem__(self , idx):\r\n",
        "        label_path = os.path.join(self.label_dir , self.df.iloc[idx , 1])\r\n",
        "        boxes = []\r\n",
        "\r\n",
        "        with open(label_path) as f:\r\n",
        "            for label in f.readlines():\r\n",
        "                class_label , x , y , width , height = [\r\n",
        "                    float(x) if float(x) != int(float(x)) else int(x)\r\n",
        "                    for x in label.replace(\"\\n\", \"\").split()\r\n",
        "                ]\r\n",
        "                boxes.append([ x , y , width , height , class_label])\r\n",
        "\r\n",
        "        boxes = torch.tensor(boxes) \r\n",
        "\r\n",
        "        img_path = os.path.join(self.img_dir , self.df.iloc[idx , 0])\r\n",
        "        image = np.asarray(plt.imread(img_path))\r\n",
        "        image = torch.from_numpy(image).permute(2 , 0 , 1)\r\n",
        "        if self.transforms:\r\n",
        "            image = self.transforms(image)\r\n",
        "\r\n",
        "        targets = torch.zeros((self.B , self.S , self.S , 6))\r\n",
        "        for box in boxes:\r\n",
        "            iou_anchors = iou_width_height(box[2:4] , self.anchors)\r\n",
        "            anchors_indices = iou_anchors.argsort(descending=True, dim=0)        \r\n",
        "            x , y , width , height , class_label = box\r\n",
        "            has_anchor = [False for _ in range(self.B)]\r\n",
        "            for anchor_idx in anchors_indices:\r\n",
        "                anchor_on_scale = anchor_idx % self.B\r\n",
        "                S = self.S\r\n",
        "                i , j = int(S * y) , int(S * x)\r\n",
        "                anchor_taken = targets[anchor_on_scale , i , j , 0]\r\n",
        "                if not anchor_taken and not has_anchor[anchor_on_scale]:\r\n",
        "                    targets[anchor_on_scale , i , j , 0] = 1\r\n",
        "                    x_cell , y_cell = S * x - j , S * y - i\r\n",
        "                    width_cell , height_cell = (\r\n",
        "                        width * S , \r\n",
        "                        height * S\r\n",
        "                    )\r\n",
        "                    box_coordinate = torch.tensor([x_cell , y_cell , width_cell , height_cell])\r\n",
        "                    targets[anchor_on_scale , i , j , 1:5] = box_coordinate\r\n",
        "                    targets[anchor_on_scale , i , j , 5] = int(class_label)\r\n",
        "                    has_anchor[anchor_on_scale] = True\r\n",
        "\r\n",
        "                elif not anchor_taken and iou_anchors[anchor_idx] > self.ignore_iou_thresh:\r\n",
        "                    targets[anchor_on_scale , i , j , 0] = -1\r\n",
        "        return image , targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 332,
      "metadata": {
        "id": "s3JifqEsz1Hr"
      },
      "outputs": [],
      "source": [
        "anchors = [[ 0.28, 0.22], [  0.38, 0.48], [ 0.9, 0.78], [ 0.07, 0.15], [ 0.15, 0.11]]\n",
        "transform = transforms.Compose([\n",
        "                                transforms.ToPILImage() , \n",
        "                                transforms.Resize((416 , 416)) , \n",
        "                                transforms.ToTensor()\n",
        "])\n",
        "dataset = Dataset_(\n",
        "    img_dir = '/content/drive/MyDrive/Yolo_Dataset/images/' , \n",
        "    label_dir = '/content/drive/MyDrive/Yolo_Dataset/labels' , \n",
        "    csv_file = '/content/drive/MyDrive/Yolo_Dataset/train.csv' , \n",
        "    anchors = anchors , \n",
        "    transforms = transform\n",
        ")\n",
        "dataloader = torch.utils.data.DataLoader(dataset , batch_size = 1 , shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPlQjG2z1h-F"
      },
      "outputs": [],
      "source": [
        "for x , y in dataloader:\n",
        "    show_tensor_images(x)\n",
        "    #for i in y:\n",
        "    #    for j in i:\n",
        "    #        for k in j:\n",
        "    #            print(k)\n",
        "    print(y.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 334,
      "metadata": {
        "id": "vCpMjSBfAVw0"
      },
      "outputs": [],
      "source": [
        "class Loss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Loss , self).__init__()\n",
        "\n",
        "        self.mse = nn.MSELoss()\n",
        "        self.en = nn.CrossEntropyLoss()\n",
        "        self.bce = nn.BCEWithLogitsLoss()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "\n",
        "        self.lambda_class = 1\n",
        "        self.lambda_noobj = 10\n",
        "        self.lambda_obj = 1\n",
        "        self.lambda_box = 10\n",
        "\n",
        "    def forward(self , predictions , targets , anchors):\n",
        "        anchors = torch.tensor(anchors)\n",
        "        obj = targets[... , 0] == 1\n",
        "        noobj = targets[... , 0] == 0\n",
        "\n",
        "        no_obj_loss = self.mse(\n",
        "            (predictions[... , 0:1][noobj]) , (targets[... , 0:1][noobj])\n",
        "        )\n",
        "\n",
        "        anchors = anchors.reshape(1 , 5 , 1 , 1 , 2)\n",
        "        box_preds = torch.cat([self.sigmoid(predictions[... , 1:3]) , torch.exp(predictions[... , 3:5]) * anchors] , dim = -1)\n",
        "        ious = intersection_over_union(box_preds[obj] , targets[... , 1:5][obj]).detach()\n",
        "        object_loss = self.mse(self.sigmoid(predictions[... , 0:1][obj]) , ious * targets[... , 0:1][obj])\n",
        "\n",
        "        predictions[... , 1:3] = self.sigmoid(predictions[... , 1:3])\n",
        "        targets[..., 3:5] = torch.log(\n",
        "            (1e-16 + targets[..., 3:5] / anchors)\n",
        "        )  \n",
        "        box_loss = self.mse(predictions[... , 1:5][obj] , targets[... , 1:5][obj])\n",
        "\n",
        "        class_loss = self.en(\n",
        "            (predictions[... , 5:][obj]) , (targets[... , 5][obj].long())\n",
        "        )\n",
        "\n",
        "        return (\n",
        "            self.lambda_box * box_loss\n",
        "            + self.lambda_obj * object_loss\n",
        "            + self.lambda_noobj * no_obj_loss\n",
        "            + self.lambda_class * class_loss\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 335,
      "metadata": {
        "id": "NCZaN5vW0eDA"
      },
      "outputs": [],
      "source": [
        "loss_ = Loss().to(device)\n",
        "for x , y in dataloader:\n",
        "    predictions = yolo(x)\n",
        "    break\n",
        "z = loss_(predictions , y , anchors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 336,
      "metadata": {
        "id": "uDZ79UqYE45f"
      },
      "outputs": [],
      "source": [
        "yolo = YOLO().to(device)\n",
        "lr = 0.002\n",
        "betas = (0.5 , 0.999)\n",
        "opt = torch.optim.Adam(yolo.parameters() , lr=lr , betas = betas)\n",
        "epochs = 200\n",
        "display_steps = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 337,
      "metadata": {
        "id": "gP21IYWit7K0"
      },
      "outputs": [],
      "source": [
        "def train():\n",
        "    mean_yolo_loss = 0\n",
        "    cur_step = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for x , y in tqdm(dataloader):\n",
        "            x , y = x.to(device) , y.to(device)\n",
        "\n",
        "            opt.zero_grad()\n",
        "            y_ = yolo(x)\n",
        "            yolo_loss = loss_(y_ , y , anchors)\n",
        "            yolo_loss.backward()\n",
        "            opt.step()\n",
        "            \n",
        "            mean_yolo_loss += yolo_loss.item() / display_steps\n",
        "            if cur_step % display_steps == 0:\n",
        "                print(f'Epoch {epoch} , Step {cur_step} , Mean YOLO Loss {mean_yolo_loss}')\n",
        "            cur_step +=1\n",
        "        mean_yolo_loss = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esuSvhPaGbSa"
      },
      "outputs": [],
      "source": [
        "train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TE7COouGb4z"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "YOLO_v2.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
    },
    "kernelspec": {
      "display_name": "Python 3.8.2 64-bit",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}